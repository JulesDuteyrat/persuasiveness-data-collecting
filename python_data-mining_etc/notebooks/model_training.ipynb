{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_data(path_logs, path_csv):\n",
    "    data = pd.read_csv(path_csv, sep='\\t')\n",
    "    dfs = []\n",
    "    for dirname, _, filenames in os.walk(path_logs):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.csv'):\n",
    "                file_path = os.path.join(dirname, filename).replace('\\\\', '/')\n",
    "                df = pd.read_csv(file_path,sep=' ')\n",
    "                \n",
    "                row = data.loc[data['log_id'] == int(filename[:-4])] # https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
    "                # print(row)\n",
    "                arr = row.values.tolist()\n",
    "                arr.append(df)\n",
    "                dfs.append(arr)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = get_csv_data('../the-attentive-cursor-dataset/logs', '../the-attentive-cursor-dataset/groundtruth.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf = [] #note + liste des inputs\n",
    "for row in range(len(dfs)):\n",
    "    cleandf.append([dfs[row][0][2],dfs[row][1]['event'].value_counts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blur', 'click', 'contextmenu', 'copy', 'keydown', 'keyup', 'mousedown', 'mousemove', 'mouseover', 'resize', 'scroll', 'select', 'touchmove', 'touchstart']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tab = np.array(cleandf, dtype='object')\n",
    "removed = ['mouseup','focus','load','beforeunload','unload','touchend']\n",
    "for row in tab :\n",
    "    for input in removed : #liste arbitraire des actions à enlever\n",
    "        if input in row[1].keys() :\n",
    "            row[1].pop(input)\n",
    "\n",
    "#liste des actions à conserver\n",
    "all_inputs = []\n",
    "for row in tab :\n",
    "    for input in row[1].keys() :\n",
    "        if input not in all_inputs :\n",
    "            all_inputs.append(input)\n",
    "all_inputs.sort()\n",
    "print(all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor input in all_inputs :\\n    max = 0\\n    for row in tab :\\n        if input in row[1].keys() :\\n            if row[1].get(input) > max :\\n                max = row[1].get(input)\\n    for row in tab :\\n        if input in row[1].keys() :\\n            row[1][input] = row[1][input]/max\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalisation v1 (mieux que la v2)\n",
    "\"\"\"\n",
    "for input in all_inputs :\n",
    "    tmp = []\n",
    "    for row in tab :\n",
    "        if input in row[1].keys() :\n",
    "            tmp.append(row[1].get(input))\n",
    "    mean = np.mean(tmp)\n",
    "    for row in tab :\n",
    "        if input in row[1].keys() :\n",
    "            row[1][input] = row[1][input]/mean\n",
    "\n",
    "print(tab)\n",
    "\"\"\"\n",
    "#normalisation v3\n",
    "\"\"\"\n",
    "for input in all_inputs :\n",
    "    max = 0\n",
    "    for row in tab :\n",
    "        if input in row[1].keys() :\n",
    "            if row[1].get(input) > max :\n",
    "                max = row[1].get(input)\n",
    "    for row in tab :\n",
    "        if input in row[1].keys() :\n",
    "            row[1][input] = row[1][input]/max\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 1 0 ... 0 0 0]\n",
      " [3 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "tmp_all_x = [] #stock temporairement les données d'entrées\n",
    "tmp_all_y = [] #stock temporairement les données de sortie\n",
    "\n",
    "for row in tab :\n",
    "    tmp_all_x.append([])\n",
    "    for input in all_inputs :\n",
    "        if input in row[1].keys() :\n",
    "            tmp_all_x[len(tmp_all_x)-1].append(row[1].get(input))\n",
    "        else :\n",
    "            tmp_all_x[len(tmp_all_x)-1].append(0)\n",
    "    tmp_all_y.append(row[0])\n",
    "\n",
    "all_x = np.array(tmp_all_x) #données en entrée du modèle\n",
    "all_y = np.array(tmp_all_y) #données en sortie du modèle\n",
    "print(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 0\\nbad_rows = []\\nfor row in range(len(all_x)) :\\n    for element in all_x[row] :\\n        if element > 5 :\\n            i +=1\\n            bad_rows.append(row)\\n            continue\\n\\nall_x = np.delete(all_x,bad_rows, axis=0)\\nprint(all_x)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalisation v2 (la v1 est un peu mieux)\n",
    "\"\"\"\n",
    "for i in range(len(all_inputs)) :\n",
    "    print(i)\n",
    "    tmp = []\n",
    "    for row in all_x :\n",
    "        tmp.append(row[i])\n",
    "    mean = np.mean(tmp)\n",
    "    for row in all_x :\n",
    "        row[i] = row[i]/mean\n",
    "    \n",
    "print(all_x)\n",
    "\"\"\"\n",
    "\n",
    "#enlevage des données extrèmes (faire une normalisation avant)\n",
    "\"\"\"\n",
    "i = 0\n",
    "bad_rows = []\n",
    "for row in range(len(all_x)) :\n",
    "    for element in all_x[row] :\n",
    "        if element > 5 :\n",
    "            i +=1\n",
    "            bad_rows.append(row)\n",
    "            continue\n",
    "\n",
    "all_x = np.delete(all_x,bad_rows, axis=0)\n",
    "print(all_x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all used input types : \n",
      "['blur', 'click', 'contextmenu', 'copy', 'keydown', 'keyup', 'mousedown', 'mousemove', 'mouseover', 'resize', 'scroll', 'select', 'touchmove', 'touchstart']\n",
      "all removed inputs : \n",
      "['mouseup', 'focus', 'load', 'beforeunload', 'unload', 'touchend']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(len(all_inputs),))\n",
    "x = tf.keras.layers.Dense(1, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(6, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs = outputs)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "#list of inputs (uncoment to see)\n",
    "print('all used input types : ')\n",
    "print(all_inputs)\n",
    "#all_inputs correspond to all the inputs type minus\n",
    "print('all removed inputs : ')\n",
    "print(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 9 3 0 7 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.9273 - accuracy: 0.0699 - val_loss: 1.9290 - val_accuracy: 0.0550\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.8969 - accuracy: 0.0890 - val_loss: 1.8899 - val_accuracy: 0.1031\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.8586 - accuracy: 0.1444 - val_loss: 1.8383 - val_accuracy: 0.2268\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.8132 - accuracy: 0.2357 - val_loss: 1.7864 - val_accuracy: 0.3299\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.7751 - accuracy: 0.3212 - val_loss: 1.7559 - val_accuracy: 0.3986\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.7537 - accuracy: 0.3552 - val_loss: 1.7427 - val_accuracy: 0.4158\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.7422 - accuracy: 0.3659 - val_loss: 1.7331 - val_accuracy: 0.4227\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.7337 - accuracy: 0.3682 - val_loss: 1.7247 - val_accuracy: 0.4227\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.7262 - accuracy: 0.3694 - val_loss: 1.7167 - val_accuracy: 0.4227\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.7193 - accuracy: 0.3694 - val_loss: 1.7089 - val_accuracy: 0.4227\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.7129 - accuracy: 0.3705 - val_loss: 1.7017 - val_accuracy: 0.4227\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.7072 - accuracy: 0.3701 - val_loss: 1.6951 - val_accuracy: 0.4261\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.7019 - accuracy: 0.3705 - val_loss: 1.6886 - val_accuracy: 0.4261\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.6970 - accuracy: 0.3697 - val_loss: 1.6825 - val_accuracy: 0.4261\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.6925 - accuracy: 0.3701 - val_loss: 1.6772 - val_accuracy: 0.4261\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.6885 - accuracy: 0.3697 - val_loss: 1.6720 - val_accuracy: 0.4261\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.6846 - accuracy: 0.3697 - val_loss: 1.6671 - val_accuracy: 0.4261\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 1.6812 - accuracy: 0.3697 - val_loss: 1.6627 - val_accuracy: 0.4261\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.6780 - accuracy: 0.3701 - val_loss: 1.6587 - val_accuracy: 0.4261\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 1.6754 - accuracy: 0.3697 - val_loss: 1.6548 - val_accuracy: 0.4261\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(all_x, all_y, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, './model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
